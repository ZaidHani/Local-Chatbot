{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4814a764",
   "metadata": {},
   "source": [
    "This notebook will have an attempt to create an agent that uses both sql and a vector database to answer user questions within scope, and if it couldn't answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15280c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment loaded\n"
     ]
    }
   ],
   "source": [
    "# Load environment and basic libs\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "print('Environment loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf42405f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models initialized: llava:latest embeddinggemma:latest\n"
     ]
    }
   ],
   "source": [
    "# Imports for LangChain, Ollama, FAISS, and SQL\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "\n",
    "# SQL/alchemy\n",
    "from sqlalchemy import create_engine, inspect, text\n",
    "import pandas as pd\n",
    "\n",
    "# Utilities\n",
    "from base64 import b64decode\n",
    "\n",
    "# Setup Ollama endpoints and models (read from env or use sensible defaults)\n",
    "OLLAMA_BASE_URL = os.getenv('OLLAMA_BASE_URL')\n",
    "CHAT_MODEL = os.getenv('OLLAMA_CHAT_MODEL')\n",
    "EMBEDDING_MODEL = os.getenv('OLLAMA_EMBEDDING_MODEL')\n",
    "\n",
    "chat_model = ChatOllama(base_url=OLLAMA_BASE_URL, model=CHAT_MODEL)\n",
    "embeddings = OllamaEmbeddings(base_url=OLLAMA_BASE_URL, model=EMBEDDING_MODEL)\n",
    "\n",
    "print('Models initialized:', CHAT_MODEL, EMBEDDING_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f344ad9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Chroma vectorstore and created retriever\n"
     ]
    }
   ],
   "source": [
    "# Load Chroma vectorstore\n",
    "try:\n",
    "# Creating the vector database\n",
    "    vectorstore = Chroma(collection_name=\"multi_modal_rag\", embedding_function=embeddings, persist_directory='../data/chroma_db')\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    print('Loaded Chroma vectorstore and created retriever')\n",
    "except Exception as e:\n",
    "    vectorstore = None\n",
    "    retriever = None\n",
    "    print('Could not load Chroma vectorstore:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e2fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "\n",
    "db_uri = f\"mssql+pyodbc://zaid-allawanseh/InsuranceNetwork?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "db = SQLDatabase.from_uri(db_uri, schema='dbo', engine_args={'isolation_level':'READ COMMITTED'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4452dcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "\n",
    "def get_schema(_):\n",
    "    return db.get_table_info()\n",
    "\n",
    "def run_query(query):\n",
    "    print('Running this query', query)\n",
    "    result = db.run(query, execution_options={'isolation_level':'READ COMMITTED'})\n",
    "    print(result)\n",
    "    return result \n",
    "\n",
    "def write_sql_query(llm):\n",
    "    template = \"\"\"write a T-SQL query that would answer the question below based on the schema provided do NOT explain what you do. no pre-amble. Do not include any Markdown code fences (, sql, etc.). Only return the raw SQL text. Keep in mind that the database is pure text, so use the LIKE keyword instead of the equal sign, also all of the data is in Arabic, so Add 'N' when you want to query\n",
    "    {schema}\n",
    "    \n",
    "    Question: {question}\"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            ('system', '''given an input question, convert it to a T-SQL query, do NOT return anything except the query, do NOT explain what you do, no pre-amble. Do not include any Markdown code fences (, sql, etc.). Only return the raw SQL text.'''),\n",
    "            ('human', template)\n",
    "        ]\n",
    "    )\n",
    "    return (\n",
    "        RunnablePassthrough.assign(schema=get_schema)\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ab5f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query(query, llm):\n",
    "    template = '''Based on the table schema below, questoin, sql query and the sql response, write a natural language response, no pre-amble.\n",
    "    {schema}\n",
    "    \n",
    "    Questoin: {question}\n",
    "    SQL Query: {query}\n",
    "    SQL Response: {response}'''\n",
    "\n",
    "    prompt_reponse = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            ('system',\n",
    "             'given an input and a sql response, convert it to a natural language answer, if there were no answer then feel free to tell the user so.'),\n",
    "             ('human',\n",
    "              template)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    full_chain = (\n",
    "        RunnablePassthrough.assign(query=write_sql_query(llm))\n",
    "        | RunnablePassthrough.assign(\n",
    "            schema=get_schema,\n",
    "            response=lambda x: run_query(x['query']))\n",
    "        | prompt_reponse\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "        )\n",
    "    return full_chain.invoke({'question': query})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbd6361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "\n",
    "llm = ChatGroq(api_key=os.getenv('GROQ_API_KEY'), model='llama-3.3-70b-versatile') \n",
    "\n",
    "def sql_chain(query:str):    \n",
    "    \n",
    "    forbidden_statements = ['insert', 'update', 'delete', 'create', 'drop', 'alter']\n",
    "    if any(stmt in query.lower() for stmt in forbidden_statements):\n",
    "        raise ValueError(\"Please ask the agent for queries and not to modify the database.\")\n",
    "    return answer_query(query, llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb3a0ab",
   "metadata": {},
   "source": [
    "# Router AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cd569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "router_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a router between two systems:\n",
    "1. Text-to-SQL: Use for questions that include something about the medical network.\n",
    "2. RAG: Use for open-ended or descriptive questions.\n",
    "\n",
    "Decide which one should handle the query.\n",
    "Return only 'sql' or 'rag'.\n",
    "\n",
    "Query: {query}\n",
    "Decision:\n",
    "\"\"\")\n",
    "\n",
    "def decide_route(query):\n",
    "    decision = llm.invoke(router_prompt.format(query=query)).content.strip().lower()\n",
    "    return decision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4495e3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fe2acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running this query SELECT [Phone] FROM dbo.[FullNetwork] WHERE [Name] LIKE N'%اويس%' AND [Main Category] LIKE N'%أطباء%'\n",
      "[('0797113535',)]\n",
      "رقم تلفون دكتور اويس هو 0797113535.\n"
     ]
    }
   ],
   "source": [
    "from chat import chain_with_sources as rag_chain\n",
    "\n",
    "user_query = 'بدي رقم تلفون دكتور اويس'\n",
    "\n",
    "decision = decide_route(user_query)\n",
    "\n",
    "if decision == \"sql\":\n",
    "    response = sql_chain(user_query)\n",
    "else:\n",
    "    response = rag_chain.invoke(user_query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d9284c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
